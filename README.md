# Retrieval Augmented Generation (RAG) Chatbot with LangChain
This project shows a chatbot made using LLMs, LangChain, and ChromaDB. The chatbot gives answers from user questions based on presented documents using a RAG pipeline.
# Main components 
•	Use LangChain loaders and text splitters for loading and splitting documents
•	Use an LLM embedding model to embed document into chunks
•	Use a vector store (ChromaDB) for storing and retrieving chunks
•	Use a prompt template for question and answering
•	Receive results from LLM (OpenAI, Groq)
# Tools used
•	Jupyter Notebook
•	Python
•	 LangChain
•	ChromaDB
•	OpenAI 
•	HuggingFaceEmbeddings
# Project file
Question_Chatbot_project_1.ipynb. This file has all code and comments

